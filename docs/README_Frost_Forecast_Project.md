# ğŸŒ¡ï¸ F3 Innovate --- Frost Risk Forecasting Challenge (2025)

**Author:** Zhengkun LI  
**Email:** zhengkun.li3969@gmail.com  
**Affiliation:** TRIC Robotics / UF ABE / F3 Innovate Participant  
**Platform:** National Data Platform (NDP)  
**Last Updated:** 2025-11-13  
**Data Repository:**
https://github.com/CarlSaganPhD/frost-risk-forecast-challenge

------------------------------------------------------------------------

## ğŸš€ Overview

This repository hosts an end-to-end solution for the **F3 Innovate Frost
Risk Forecasting Challenge (2025)**.\
The objective is to develop probabilistic, spatially-generalizable frost
risk models using 15 years of hourly meteorological data from 18 CIMIS
stations across California.

The project integrates **station-level time series**, **geospatial
topography**, and **reanalysis synoptic fields** into a
**spatio-temporal deep learning pipeline**.

------------------------------------------------------------------------

## ğŸ§¾ Executive Summary

- **Goal**: deliver calibrated probabilistic frost forecasts (3h/6h/12h/24h horizons) with quantified uncertainty and LOSO generalization.
- **Primary Deliverables**: reproducible data pipeline, multi-model training stack, evaluation reports, deployment-ready inference services (batch + API).
- **Stakeholders**: F3 Innovate challenge organizers, specialty crop growers, TRIC Robotics field teams.
- **Decision Support**: configurable frost thresholds, reliability curves, and station-level alerts integrate with grower workflows.

------------------------------------------------------------------------

## ğŸ“¦ Status & Deliverables

  Item                        Owner         Status      Output / Location
  --------------------------  ------------  ----------  ----------------------------------------------------
  Data acquisition            Z. Li         âœ… Complete  `data/raw/`, `data/external/`
  QC & exploratory analysis   Z. Li         âœ… Complete  `docs/DATA_DOCUMENTATION.md`, `docs/figures/`
  Feature engineering         Z. Li         âœ… Complete  298 features, `docs/FEATURE_ENGINEERING.md`, `docs/FEATURE_REFERENCE.md`
  Training pipelines          Z. Li         âœ… Complete  `scripts/train/train_frost_forecast.py`
  Model training              Z. Li         âœ… Complete  LightGBM (Top 175), XGBoost (in progress)
  LOSO evaluation             Z. Li         âœ… Complete  `experiments/lightgbm/top175_features/lightgbm/loso/`
  Inference services          Z. Li         âœ… Complete  `scripts/inference/predict_frost.py`
  Reporting & documentation   Z. Li         âœ… Complete  `docs/report/`, comprehensive analysis reports

------------------------------------------------------------------------

## ğŸ”„ Data Processing Pipeline

1. **Raw ingestion** â†’ pull hourly CIMIS observations, station metadata, and ERA5/HRRR reanalysis tiles into `data/raw/` and `data/external/`.
   - Sources: CIMIS API dumps, `scripts/fetch_station_metadata.py`, ERA5/HRRR NetCDF (planned ingestion via `src/data_prep/download_reanalysis.py`).
2. **Quality control & cleaning** â†’ decode QC flags, replace sentinel values, harmonize timestamps, and write clean intermediates to `data/interim/`.
   - Assets: `scripts/generate_data_report.py`, exploratory notebooks in `notebooks/eda/`.
   - Outputs: `data/processed/station_overview.csv`, `data/processed/missing_by_station.csv`, QA plots in `docs/figures/`.
3. **Feature engineering** â†’ derive traditional frost indicators (e.g., growing degree hours, rolling minima, humidity deficits), radiative proxies, synoptic summaries, and topo-climatic descriptors; persist feature tensors to `data/processed/`.
   - Planned scripts: `src/data_prep/features_tabular.py`, `src/data_prep/features_grid.py`.
   - Outputs: `data/processed/tabular_features.parquet`, `data/processed/gridded_patches.zarr`.
4. **Dataset assembly** â†’ merge targets and features, build LOSO splits, and export train/val/test manifests for tabular and deep-learning pipelines.
   - Manifests: `data/processed/splits/lo_station_<id>.json`.
   - Metadata: `docs/data_catalog.md` (to capture column dictionary, feature provenance).

------------------------------------------------------------------------

## ğŸ§© Core Goals

  -----------------------------------------------------------------------
  Objective                        Description
  -------------------------------- --------------------------------------
  Frost Event Forecasting          Predict frost event probability (T \<
                                   0 Â°C) and Tmin for 3h, 6h, 12h, and
                                   24h horizons.

  Calibration & Reliability        Quantify uncertainty using Brier, ECE,
                                   PR-AUC, ROC-AUC, and Reliability
                                   Diagrams.

  Spatial Generalization (LOSO)    Evaluate how well models transfer to
                                   unseen CIMIS stations.

  Synoptic Integration             Fuse ERA5/HRRR cold-air advection,
                                   cloud cover, and radiative cooling
                                   fields.

  Interpretability & Decision      Provide calibrated probabilities and
  Support                          actionable thresholds.
  -----------------------------------------------------------------------

------------------------------------------------------------------------

## ğŸ§  Modeling Framework & Baselines

### Traditional Feature Engineering Baseline

  Feature Block           Examples / Notes                                       Status
  ----------------------  -----------------------------------------------------  --------------------------------
  Temporal indicators     Lagged Tmin/Tdew (1â€“24 h), rolling minima/maxima,      Specification drafted, implementation in progress
                          diurnal amplitude, chilling hours, freeze duration
  Humidity & radiation    Vapor pressure deficit, saturation deficit,            Derived from station history + ERA5 cloud cover
                          longwave cooling proxy, clear-sky radiation residuals
  Dynamics                Cold-air advection magnitude, pressure tendency,       Requires ERA5/HRRR gradients (planned)
                          wind shift flags, Richardson number estimates
  Topo-climatic context   Elevation, slope, aspect, cold-air pooling index,      DEM ingestion pipeline planned
                          distance to water bodies/valleys
  Persistence heuristics  Historical Tmin quantiles for day-of-year, analog      Utilizes 15-year archive; will be cached in feature store
                          matching scores

- **Implementation**: pipeline in `src/data/feature_engineering.py` producing 298 features; models in `src/models/ml/`.
- **Modeling stack**: LightGBM and XGBoost with calibrated probabilities, comprehensive feature importance analysis.
- **Feature Selection**: Top 175 features (90% importance) identified and used for final models.
- **Results**: Excellent performance with ROC-AUC > 0.98 for all horizons, excellent spatial generalization (LOSO).

### Deep & Hybrid Models

1.  Temporal Sequence Models (LSTM / TCN)
    - Multi-horizon decoder predicting Tmin and frost probabilities jointly; Lightning modules under `src/models/temporal/`.
2.  Image-Based Models (CNN â†’ TCN / ConvLSTM)
    - Process ERA5/HRRR patches, export embeddings for downstream fusion.
3.  Spatio-Temporal Graph Neural Networks (ST-GNN)
    - Nodes represent stations, edges weighted by topographic and meteorological affinity.
4.  Hybrid Fusion (CNN Embeddings + GBDT)
    - Combines deep synoptic embeddings with engineered tabular features through LightGBM.
5.  Reliability Calibration
    - Platt scaling, isotonic regression, and conformal wrappers applied per station/horizon.

------------------------------------------------------------------------

## ğŸ§­ Validation: Leave-One-Station-Out (LOSO)

Each run excludes one station as a completely unseen test site.\
Performance is summarized as **mean Â± SD across 18 stations**, plus
per-station tables.

------------------------------------------------------------------------

## â„ï¸ Frost Label Configuration

- Default frost event definition: `Tmin < 0â€¯Â°C`.
- Configurable thresholds via Hydra config group `labels.threshold_c` to support crop-specific risk bands (e.g., -2â€¯Â°C for almonds, +1â€¯Â°C for berries).
- Supports multi-level targets (`frost_warn`, `frost_alert`) emitted alongside continuous Tmin regression labels.

------------------------------------------------------------------------

## âš™ï¸ Implementation Stack

  Component         Library / Framework
  ----------------- ----------------------------------------------------
  Data Processing   pandas, geopandas, rasterio, shapely
  ML / DL           PyTorch, PyTorch Lightning, scikit-learn, LightGBM
  Visualization     matplotlib, seaborn, plotly
  Reproducibility   Jupyter, Hydra configs, Makefile
  Environment       Python â‰¥3.10, CUDA â‰¥12, RTX 5090 GPU

------------------------------------------------------------------------

## ğŸ“ˆ Experiments

  Track                         Description / Notes                                 Status
  ----------------------------  --------------------------------------------------- --------------------------------------
  Baseline tabular models       LightGBM, XGBoost, logistic regression ensembles;   Feature spec complete, training scripts in progress
                               benchmark against climatology and persistence
  Temporal deep models          TCN, LSTM, Seq2Seq with attention for multi-horizon Prototyping in `notebooks/models/temporal.ipynb`
                               Tmin + probability outputs
  Synoptic image encoders       CNN â†’ TCN / ConvLSTM on ERA5/HRRR patches           Data loader under development
  ST-GNN                        Graph Neural Network leveraging station topology    Architecture drafted, pending implementation
  Hybrid fusion                 Combine CNN embeddings with engineered features      Design finalized; awaiting export pipeline
  Calibration & conformal       Reliability diagrams, Platt, isotonic, conformal    Baseline scripts in `notebooks/calibration/`
  Ablation studies              Feature block removal, threshold sensitivity        Planned once baselines stabilize
  LOSO benchmarking             Aggregate metrics meanÂ±SD; per-station dashboards   Template dashboard in `docs/figures/lo_station_demo.png`

------------------------------------------------------------------------

## ğŸ§¾ Project Structure

    frost-risk-forecast-challenge/
    â”œâ”€â”€ data/                    # æ•°æ®ç›®å½•
    â”‚   â”œâ”€â”€ raw/                 # åŸå§‹æ•°æ®
    â”‚   â”œâ”€â”€ interim/             # ä¸­é—´æ•°æ®
    â”‚   â””â”€â”€ processed/           # å¤„ç†åçš„æ•°æ®
    â”œâ”€â”€ src/                     # æºä»£ç 
    â”‚   â”œâ”€â”€ data/                # æ•°æ®åŠ è½½ã€æ¸…æ´—ã€ç‰¹å¾å·¥ç¨‹
    â”‚   â”œâ”€â”€ models/              # æ¨¡å‹å®ç°ï¼ˆLightGBM, XGBoostç­‰ï¼‰
    â”‚   â”œâ”€â”€ evaluation/          # è¯„ä¼°æŒ‡æ ‡å’ŒéªŒè¯æ–¹æ³•
    â”‚   â”œâ”€â”€ visualization/       # å¯è§†åŒ–å·¥å…·
    â”‚   â””â”€â”€ utils/               # å·¥å…·å‡½æ•°
    â”œâ”€â”€ scripts/                 # è„šæœ¬ç›®å½•
    â”‚   â”œâ”€â”€ train/               # è®­ç»ƒè„šæœ¬
    â”‚   â”œâ”€â”€ inference/           # æ¨ç†è„šæœ¬
    â”‚   â”œâ”€â”€ evaluate/            # è¯„ä¼°è„šæœ¬
    â”‚   â””â”€â”€ data_prep/           # æ•°æ®å‡†å¤‡è„šæœ¬
    â”œâ”€â”€ experiments/             # å®éªŒç»“æœ
    â”‚   â”œâ”€â”€ lightgbm/            # LightGBMæ¨¡å‹
    â”‚   â”‚   â”œâ”€â”€ feature_importance/  # ç‰¹å¾é‡è¦æ€§åˆ†æ
    â”‚   â”‚   â””â”€â”€ top175_features/    # Top 175ç‰¹å¾é…ç½®
    â”‚   â”‚       â”œâ”€â”€ full_training/  # æ ‡å‡†è¯„ä¼°
    â”‚   â”‚       â””â”€â”€ loso/          # LOSOè¯„ä¼°
    â”‚   â””â”€â”€ xgboost/              # XGBoostæ¨¡å‹
    â”‚       â””â”€â”€ top175_features/    # Top 175ç‰¹å¾é…ç½®
    â”‚           â””â”€â”€ full_training/  # æ ‡å‡†è¯„ä¼°
    â”œâ”€â”€ config/                  # é…ç½®æ–‡ä»¶
    â”œâ”€â”€ docs/                    # æ–‡æ¡£ç›®å½•
    â”‚   â”œâ”€â”€ report/              # åˆ†ææŠ¥å‘Š
    â”‚   â””â”€â”€ figures/             # å›¾è¡¨
    â”œâ”€â”€ tests/                   # æµ‹è¯•ä»£ç 
    â””â”€â”€ README.md                # é¡¹ç›®è¯´æ˜ï¼ˆæœ¬æ–‡ä»¶ï¼‰

------------------------------------------------------------------------

## ğŸ“š Documentation

### ä¸»è¦æ–‡æ¡£ï¼ˆå·²é‡æ–°ç»„ç»‡ï¼‰

**ç”¨æˆ·æ–‡æ¡£**:
- **[USER_GUIDE.md](USER_GUIDE.md)**: å®Œæ•´ç”¨æˆ·æŒ‡å— - ä»ç¯å¢ƒè®¾ç½®ã€å¿«é€Ÿå¼€å§‹åˆ°é«˜çº§ä½¿ç”¨

**æŠ€æœ¯æ–‡æ¡£**:
- **[TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md)**: æŠ€æœ¯æ–‡æ¡£ - æ¶æ„è®¾è®¡ã€APIå‚è€ƒã€é…ç½®ç®¡ç†

**æ•°æ®æ–‡æ¡£**:
- **[DATA_DOCUMENTATION.md](DATA_DOCUMENTATION.md)**: æ•°æ®æ–‡æ¡£ - æ•°æ®æ¦‚è§ˆã€QCå¤„ç†ã€å˜é‡ä½¿ç”¨æƒ…å†µ

**ç‰¹å¾å·¥ç¨‹**:
- **[FEATURE_ENGINEERING.md](FEATURE_ENGINEERING.md)**: ç‰¹å¾å·¥ç¨‹æ–‡æ¡£ - ç‰¹å¾è®¾è®¡ã€å®ç°å’Œåˆ†æ
- **[FEATURE_REFERENCE.md](FEATURE_REFERENCE.md)**: ç‰¹å¾å‚è€ƒæ–‡æ¡£ - å®Œæ•´çš„ç‰¹å¾åˆ—è¡¨ã€è·å–æ–¹æ³•å’ŒåŠŸèƒ½è¯´æ˜ï¼ˆ298ä¸ªç‰¹å¾ï¼‰

**è®­ç»ƒå’Œè¯„ä¼°**:
- **[TRAINING_AND_EVALUATION.md](TRAINING_AND_EVALUATION.md)**: è®­ç»ƒå’Œè¯„ä¼°æ–‡æ¡£ - è®­ç»ƒé…ç½®ã€LOSOè¯„ä¼°ã€æ€§èƒ½å¯¹æ¯”ã€ç‰¹å¾å·¥ç¨‹å’ŒLOSOçš„å…³ç³»

### å…¶ä»–æ–‡æ¡£

**é¡¹ç›®çŠ¶æ€**:
- **[PROJECT_STATUS.md](PROJECT_STATUS.md)**: é¡¹ç›®çŠ¶æ€æ€»è§ˆï¼ˆå†å²æ–‡æ¡£ï¼Œä¸»è¦çŠ¶æ€ä¿¡æ¯è§æœ¬READMEï¼‰

**å¿«é€Ÿå¼€å§‹**:
```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆæ¨èï¼‰
python3 scripts/train/train_frost_forecast.py \
    --horizons 3 6 12 24 \
    --model lightgbm \
    --output experiments/lightgbm/top175_features/lightgbm \
    --top-k-features 175

# è¿è¡ŒLOSOè¯„ä¼°
python3 scripts/train/train_frost_forecast.py \
    --horizons 3 6 12 24 \
    --model lightgbm \
    --loso \
    --save-loso-models \
    --output experiments/lightgbm/top175_features/lightgbm \
    --top-k-features 175
```

è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·å‚è€ƒ [USER_GUIDE.md](USER_GUIDE.md)ã€‚

## ğŸ§® Results Summary

### LightGBM (Top 175 Features) - Standard Evaluation

  Horizon   Brier â†“   ECE â†“   ROC-AUC â†‘   PR-AUC â†‘   MAE â†“   RMSE â†“   RÂ² â†‘
  --------- --------- ------- ----------- ---------- -------- -------- --------
  3h        0.0028    0.0015   0.9965      0.9965     1.14     1.52     0.9703
  6h        0.0040    0.0025   0.9926      0.9926     1.55     2.02     0.9481
  12h       0.0043    0.0025   0.9892      0.9892     1.79     2.33     0.9304
  24h       0.0060    0.0048   0.9843      0.9843     1.93     2.51     0.9196

### LightGBM (Top 175 Features) - LOSO Evaluation

  Horizon   ROC-AUC â†‘   MAE â†“   RMSE â†“   RÂ² â†‘
  --------- ----------- -------- -------- --------
  3h        0.9974     1.14     1.52     0.9703
  6h        0.9938     1.55     2.02     0.9481
  12h       0.9905     1.79     2.33     0.9304
  24h       0.9878     1.93     2.51     0.9196

**å…³é”®å‘ç°**:
- âœ… ä¼˜ç§€çš„ç©ºé—´æ³›åŒ–èƒ½åŠ›ï¼ˆLOSO ROC-AUC > 0.98 å¯¹æ‰€æœ‰æ—¶é—´çª—å£ï¼‰
- âœ… å‡ºè‰²çš„æ¦‚ç‡æ ¡å‡†ï¼ˆBrier Score < 0.01ï¼ŒECE < 0.005ï¼‰
- âœ… é«˜ç²¾åº¦æ¸©åº¦é¢„æµ‹ï¼ˆMAE < 2Â°Cï¼ŒRÂ² > 0.91ï¼‰

è¯¦ç»†ç»“æœè¯·å‚è€ƒ [docs/report/LIGHTGBM_ANALYSIS.md](report/LIGHTGBM_ANALYSIS.md) å’Œ [docs/report/CALIBRATION_AND_RELIABILITY_REPORT.md](report/CALIBRATION_AND_RELIABILITY_REPORT.md)ã€‚

------------------------------------------------------------------------

## âš™ï¸ Configuration & Experiment Management

- **Hydra config tree**

      configs/
      â”œâ”€â”€ train/
      â”‚   â”œâ”€â”€ tabular_baseline.yaml
      â”‚   â”œâ”€â”€ cnn_tcn.yaml
      â”‚   â””â”€â”€ stgnn.yaml
      â”œâ”€â”€ data/
      â”‚   â”œâ”€â”€ loaders/
      â”‚   â”‚   â””â”€â”€ cimis_station.yaml
      â”‚   â””â”€â”€ transforms/
      â””â”€â”€ labels/
          â””â”€â”€ threshold_c.yaml

- **Sample training config (`configs/train/tabular_baseline.yaml`)**

      defaults:
        - data: loaders/cimis_station
        - model: lightgbm_baseline
        - labels: threshold_c@labels=zero_celsius
      trainer:
        max_epochs: 120
        callbacks:
          - type: early_stopping
            monitor: val/brier
            patience: 10
      station_split:
        strategy: loso
        holdout_station: ${station.id}

- **Experiment tracking**
  - PyTorch Lightning loggers integrated with MLflow (primary) and Weights & Biases (optional).
  - Naming convention: `{model_type}-{feature_version}-st{station_id}`; metrics aggregated via `scripts/aggregate_metrics.py`.
- **Automation**
  - `Makefile` targets wrap Hydra commands (`make train MODEL=cnn_tcn STATION=47`).
  - `scripts/run_sweep.py` launches multi-station sweeps; results synced to `reports/experiments/<date>/`.
- **Reproducibility controls**
  - Seed management through Hydra (`+seed=1234`), deterministic CuDNN toggles in Lightning utilities, environment locked via `poetry.lock`.

------------------------------------------------------------------------

## ğŸ§© Deployment

**Batch Inference**

``` bash
python -m src.infer.batch_infer --checkpoints runs/cnn_tcn/best.ckpt --inputs data/processed/patches.zarr --out outputs/preds.parquet
```

1. **Environment**: `conda env create -f environment.yaml` (CUDA â‰¥13), followed by `poetry install` to sync exact package pins.
2. **Inputs**: requires LOSO manifest, feature parquet/zarr, and metadata; support for cloud sync via `aws s3 sync` or `gsutil rsync`.
3. **Outputs**: parquet/feather containing `[timestamp, station_id, horizon_hr, p_frost, tmin_pred, model_version, data_version]`.
4. **Scheduling**: Airflow DAG `dags/frost_batch.py` (planned) executes hourly; fallback cron script `cron/forecast_batch.sh`.

**API Service**

``` bash
docker build -t frost:latest -f docker/Dockerfile .
docker run --gpus all -p 8000:8000 frost:latest python -m src.infer.serve_api
```

1. **Image**: base `nvidia/cuda:13.0.0-runtime-ubuntu22.04`, installs Poetry deps, copies `src/` and `configs/`.
2. **Runtime**: mount `/models` for checkpoint hot-swap; environment variables (`MODEL_PATH`, `THRESHOLD_C`) injected via secrets manager.
3. **Endpoints**:
   - `POST /v1/forecast`: accepts JSON payload with recent observations; returns multi-horizon probabilities + Tmin forecasts.
   - `GET /v1/healthz`: readiness/liveness probe for Kubernetes.
4. **Deployment targets**: on-prem GPU node (RTX 5090) or cloud (GCP A2, AWS g5). Terraform manifests planned under `infra/`.
5. **Monitoring**: Prometheus metrics (`forecast_latency_ms`, `probability_shift`, `api_errors_total`), structured logging to Loki/CloudWatch.

------------------------------------------------------------------------

## ğŸ“Š Operations, Monitoring & Maintenance

- **Data freshness**: nightly sync validates new CIMIS observations; alerts fire if any station lags >3 hours.
- **Model drift**: rolling Brier score and calibration error monitored; auto-retrain triggered when degradation exceeds 10% from baseline.
- **Incident response**: runbooks (planned `docs/runbooks/frost_alerts.md`) define escalation within 30 minutes to agronomy lead.
- **Security & compliance**: secrets injected via `.env` and Vault/SSM; Mapbox tokens kept out of version control with IAM-scoped access.

------------------------------------------------------------------------

## ğŸ› ï¸ Hardware & Environment Guidelines

- **Reference workstation**: AMD Ryzen 9 9950X, 64â€¯GB RAM, NVIDIA RTX 5090 (32â€¯GB VRAM), driver 580.95.05, CUDA 13.
- **Minimum training spec**: 16â€¯GB VRAM GPU (RTX 4080 / A4000) with mixed precision; adjust batch sizes to hold <12â€¯GB usage.
- **Batch inference footprint**: <4â€¯GB VRAM, <2â€¯GB RAM; throughput â‰ˆ250 station-horizon forecasts/s on RTX 5090.
- **Scaling**: PyTorch Lightning DDP for multi-GPU; Ray Tune integration planned for hyperparameter sweeps; parquet + Arrow optimize IO.

------------------------------------------------------------------------

## ğŸ§­ Roadmap & Next Steps

- Finalize feature engineering scripts and publish `docs/data_catalog.md`.
- Implement full Hydra/Lightning pipelines with MLflow logging and artifact versioning.
- Automate ERA5/HRRR ingestion and QC checkpoints.
- Build CI/CD (GitHub Actions) to lint, test, containerize, and push inference images.
- Develop Streamlit/Plotly dashboards for LOSO evaluation and station-level monitoring.

------------------------------------------------------------------------

## ğŸ§­ Research Vision

Paper title: *Evaluating Spatial Generalization of Frost Forecast Models
Across California: A Multi-Modal Deep Learning Benchmark.*

------------------------------------------------------------------------

## ğŸ§¾ License

MIT License --- For research and educational use.

------------------------------------------------------------------------

## ğŸ› ï¸ Unified Training & Inference Interface

- **Hydra Configs**: centralize experiment settings under `configs/`, enabling reproducible sweeps (e.g., `python -m src.train.run --config-name tabular_baseline station=71`).
- **Lightning Trainers**: wrap PyTorch modules with Lightning for checkpointing, early stopping, and mixed precision; shared callbacks ensure consistent logging across models.
- **API Alignment**: standardize `fit()`, `predict_proba()`, and `forecast()` signatures for tabular and deep models, simplifying downstream evaluation and deployment.
