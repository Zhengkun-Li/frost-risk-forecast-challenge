# 训练和评估文档

**最后更新**: 2025-11-12

本文档详细说明模型训练、评估、监控和性能对比。

## 📋 目录

1. [训练配置](#训练配置)
2. [LOSO 评估](#loso-评估)
3. [训练监控](#训练监控)
4. [性能对比](#性能对比)
5. [采样方法说明](#采样方法说明)
6. [特征工程和LOSO的关系](#特征工程和loso的关系)

---

## 训练配置

### 硬件配置

- **GPU**: NVIDIA RTX 5090 (32GB)
- **CPU**: AMD 9950 (32核)
- **内存**: 60GB

### 数据规模

- **总数据量**: 2,367,360 行
- **站点数**: 18
- **时间范围**: 2010-09-28 到 2025-09-28 (15年数据)

### 模型配置优化

```python
{
    "n_estimators": 200,
    "learning_rate": 0.05,
    "max_depth": 8,
    "num_leaves": 63,
    "n_jobs": 8,  # 限制CPU核心使用（避免内存溢出）
    "force_col_wise": True,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "reg_alpha": 0.1,
    "reg_lambda": 0.1,
}
```

### 启动训练

```bash
./scripts/run_with_venv.sh scripts/train/train_frost_forecast.py \
    --horizons 3 6 12 24 \
    --loso \
    --output experiments/full_data_training \
    --model lightgbm
```

### 预计训练时间

- **数据加载**: ~2-5分钟
- **数据清洗**: ~5-10分钟
- **特征工程**: ~30-60分钟
- **标准评估训练** (4个时间窗口): ~40-80分钟
- **LOSO评估训练** (18个站点 × 4个时间窗口): ~180-360分钟 (3-6小时)

**总预计时间** (包含LOSO评估): **4-7小时**

**注意**：
- 如果不运行LOSO评估（不使用`--loso`参数），总时间约为**1.5-2.5小时**
- 如果运行LOSO评估，总时间约为**4-7小时**（LOSO评估需要额外3-6小时）

### 训练时间对比

#### 标准评估（Standard Evaluation）

| 项目 | 值 | 说明 |
|------|-----|------|
| **模型数量** | 8个 | 4个时间窗口 × 2个模型（分类+回归） |
| **每个模型配置** | 200棵树, max_depth=8, num_leaves=63 | 较复杂的模型 |
| **训练数据** | 70%的数据（约1.66M行） | 时间序列划分 |
| **测试数据** | 15%的数据（约355K行） | 时间序列划分 |
| **每个模型训练时间** | ~10分钟 | 基于200棵树 |
| **总训练时间** | ~80分钟 | 8个模型 × 10分钟 |

#### LOSO评估（LOSO Evaluation）

| 项目 | 值 | 说明 |
|------|-----|------|
| **模型数量** | 144个 | 18个站点 × 4个时间窗口 × 2个模型 |
| **每个模型配置** | 50棵树, max_depth=6, num_leaves=31 | 更简单的模型（1/4复杂度） |
| **训练数据** | 17个站点的全部数据（约2.24M行，94%数据） | 按站点划分 |
| **测试数据** | 1个站点的全部数据（约131K行，6%数据） | 按站点划分 |
| **每个模型训练时间** | ~2.5分钟 | 基于50棵树（约标准评估的1/4） |
| **总训练时间** | ~360分钟 (6小时) | 144个模型 × 2.5分钟 |

#### 时间对比分析

| 对比项 | 标准评估 | LOSO评估 | 比例 |
|--------|---------|----------|------|
| **模型数量** | 8个 | 144个 | **18倍** |
| **每个模型树数** | 200棵 | 50棵 | **1/4** |
| **每个模型训练时间** | ~10分钟 | ~2.5分钟 | **1/4** |
| **总训练时间** | ~80分钟 | ~360分钟 | **4.5倍** |

#### 为什么不是18倍？

虽然LOSO评估需要训练**18倍数量的模型**（144个 vs 8个），但总训练时间只有**4.5倍**，原因如下：

1. **模型复杂度降低**：
   - 标准评估：200棵树, max_depth=8, num_leaves=63
   - LOSO评估：50棵树, max_depth=6, num_leaves=31
   - 每个LOSO模型的复杂度约为标准评估的**1/4**

2. **训练时间计算**：
   ```
   模型数量比：18倍
   每个模型时间比：1/4倍
   总时间比：18 × (1/4) = 4.5倍
   ```

3. **实际考虑**：
   - LOSO评估使用更多训练数据（17个站点 ≈ 94%数据 vs 70%数据）
   - 但模型更简单（50棵树 vs 200棵树），训练更快
   - 因此总训练时间约为标准评估的**4-6倍**，而不是18倍

#### 优化说明

- LOSO评估使用更简单的模型配置（50棵树）来平衡准确性和训练时间
- 如果需要更高精度，可以增加`n_estimators`（如增加到100或150），但训练时间会相应增加
- 当前配置（50棵树）已经能够提供良好的跨站点泛化性能

#### 总结

**回答您的问题**：
- ✅ **LOSO评估使用整个数据集**（不是只在15%测试集上）
- ✅ **LOSO评估需要训练18倍数量的模型**（144个 vs 8个）
- ❌ **但LOSO训练时间不是18倍，而是约4.5倍**

**原因**：
- 虽然模型数量是18倍，但每个LOSO模型更简单（50棵树 vs 200棵树）
- 每个模型训练时间约为标准评估的1/4
- 总时间 = 18倍模型数 × 1/4复杂度 = **4.5倍**

### 训练时间窗口

- **3小时窗口**: 预测未来3小时的霜冻概率和温度
- **6小时窗口**: 预测未来6小时的霜冻概率和温度
- **12小时窗口**: 预测未来12小时的霜冻概率和温度
- **24小时窗口**: 预测未来24小时的霜冻概率和温度

### 评估方法

系统使用**两种独立的评估方法**：

1. **标准评估（Standard Evaluation）**：
   - 使用**时间序列划分**（70% 训练，15% 验证，15% 测试）
   - 在**测试集（15%的数据）**上评估模型性能
   - 用于评估模型在时间序列上的预测能力

2. **LOSO评估（Leave-One-Station-Out Evaluation）**：
   - 使用**整个数据集**，**独立于**时间序列划分
   - 按**站点划分**，而不是按时间划分
   - 对于每个站点：
     - **训练集** = 其他所有站点的**全部数据**（包含所有时间点）
     - **测试集** = 当前站点的**全部数据**（包含所有时间点）
   - 用于评估模型在**未见站点**上的泛化能力

**重要说明**：
- LOSO评估**不是**在15%的测试数据集上工作的
- LOSO评估使用**整个数据集**，但是按**站点**划分，而不是按**时间**划分
- 这两种评估方法是**独立的**，可以同时进行

### 采样方法说明

#### 问题

当进行基于100k样本的特征分析时，这些样本是来自不同站点还是仅来自一个站点？

#### 答案

特征重要性分析基于**来自18个不同站点的100k样本**，而不是单个站点。

#### 采样方法

**代码实现**:

在 `scripts/train/train_frost_forecast.py` 中，采样使用：

```python
# Line 59-62
if sample_size and sample_size < len(df):
    df = df.sample(n=sample_size, random_state=42)
    print(f"Sampled {len(df)} rows")
```

**方法**: `df.sample(n=sample_size, random_state=42)`  
**类型**: 从整个数据集的随机采样（不按站点分层）  
**结果**: 虽然是随机的，但100k样本在各站点之间相对平衡

#### 实际站点分布

**统计（来自100k样本分析）**:

- **总样本数**: 100,000
- **站点数**: 18（所有可用站点）
- **每个站点平均样本数**: ~5,556
- **每个站点最小样本数**: 5,455
- **每个站点最大样本数**: 5,784
- **标准差**: 75
- **变异系数 (CV)**: 1.35%

#### 分布质量

✅ **高度平衡**: CV = 1.35% 表明跨站点分布非常均匀

**解释**:
- CV < 20%: 平衡采样 ✅
- CV 20-50%: 中等不平衡 ⚠️
- CV > 50%: 不平衡采样 ❌

#### 为什么是平衡的？

尽管采样是随机的（不按站点分层），但结果是平衡的，因为：

1. **原始数据平衡**: 完整数据集可能每个站点有相似数量的数据
2. **大样本量**: 100k足够大，随机采样接近总体分布
3. **随机状态**: 使用 `random_state=42` 确保可重现性

#### 对特征重要性分析的影响

**✅ 优势**:

1. **多站点表示**: 
   - 特征重要性反映**所有18个站点**的模式
   - 不偏向单个站点的特征

2. **空间泛化**:
   - 捕获跨站点模式
   - 站点特征（纬度、经度、海拔）具有现实重要性

3. **时间模式**:
   - 包括来自不同站点的各种时间段
   - 更好地表示季节和日周期

4. **稳健性**:
   - 特征排名不太可能是站点特定的
   - 更可泛化到新站点

**⚠️ 局限性**:

1. **不分层**:
   - 采样不是明确按站点平衡的
   - 某些站点可能有稍多/少的表示

2. **站点特定模式**:
   - 可能错过站点特定的特征重要性
   - 应该使用LOSO（Leave-One-Station-Out）评估进行验证

3. **时间覆盖**:
   - 可能不能均匀表示所有时间段
   - 随机采样可能错过某些季节模式

#### 比较：单站点 vs 多站点

| 方面 | 单站点 | 多站点（当前） |
|------|--------|---------------|
| **表示** | 仅一个站点 | 18个站点 |
| **泛化** | 站点特定 | 跨站点 |
| **空间特征** | 不太重要 | 更现实 |
| **稳健性** | 较低 | 较高 |
| **验证** | 更容易 | 更复杂 |

#### 建议

**当前分析（多站点100k样本）**:

✅ **适用于**:
- 一般特征重要性理解
- 初始特征选择
- 理解跨站点模式

**额外分析推荐**:

为了更全面的理解：

1. **单站点分析**:
   - 分别分析每个站点的特征重要性
   - 识别站点特定模式

2. **LOSO评估**:
   - 在17个站点上训练并在1个站点上测试时评估特征重要性
   - 评估空间泛化

3. **时间分析**:
   - 按季节/时间段分析特征重要性
   - 识别时间相关模式

#### 结论

特征重要性分析基于**来自18个不同站点的100k样本**，分布相对平衡（CV = 1.35%）。这提供：

✅ 多站点表示  
✅ 跨站点特征重要性  
✅ 更好的空间泛化  
✅ 更稳健的特征排名  

但是，对于最终模型部署，考虑：
- 站点特定的特征分析
- LOSO评估用于空间泛化
- 时间特征重要性分析

---

## LOSO 评估

### 概述

LOSO (Leave-One-Station-Out) 评估用于测试模型在未见站点上的泛化能力。本实现确保**无数据泄漏**。

### 数据划分方式

LOSO评估使用**整个数据集**，按站点划分：

```python
from src.evaluation.validators import CrossValidator

# 生成 LOSO 划分（使用整个数据集）
loso_splits = CrossValidator.leave_one_station_out(df)
# 返回: List[(train_df, test_df)]
# train_df: 其他所有站点的全部数据（所有时间点）
# test_df: 单个测试站点的全部数据（所有时间点）
```

**示例**：
- 对于站点2：
  - 训练集 = 站点 7, 15, 39, 47, ... 的所有数据（17个站点 × 131,520小时）
  - 测试集 = 站点 2 的所有数据（1个站点 × 131,520小时）

### 无数据泄漏保证

1. **预处理独立**：每个 LOSO fold 中，预处理器只在训练站点上拟合
2. **测试站点隔离**：测试站点的数据不参与任何训练阶段的拟合
3. **特征工程一致**：特征工程步骤在训练和测试上保持一致，但参数只从训练数据学习

### 评估指标

**分类/概率指标**（霜冻预测）：
- Brier Score, ECE, ROC-AUC, PR-AUC, Accuracy, Precision, Recall, F1

**回归指标**（温度预测）：
- MAE, RMSE, R², MAPE

### 汇总统计

跨所有站点计算：
- **均值 (mean)**: 所有站点的平均指标值
- **标准差 (std)**: 指标的标准差
- **最小值 (min)**: 最佳站点表现
- **最大值 (max)**: 最差站点表现

### 结果文件

- `loso/summary.json`: 汇总统计
- `loso/station_metrics.csv`: 每个站点的详细指标

---

## 训练监控

### 详细监控（推荐）

```bash
./scripts/monitor_training_detailed.sh
```

**功能**：
- ✅ 总体进度百分比
- ✅ 当前阶段进度百分比
- ✅ 可视化进度条
- ✅ 预计剩余时间（ETA）
- ✅ 当前训练阶段
- ✅ CPU、内存、GPU使用率
- ✅ 每2秒自动刷新

### 简单监控

```bash
./scripts/monitor_training.sh
```

### 查看日志

```bash
# 查看实时日志
tail -f /tmp/full_training.log

# 查看关键进度
tail -f /tmp/full_training.log | grep -E "(Step|Training|Features|Samples)"
```

### 检查进程状态

```bash
# 检查进程是否运行
ps aux | grep train_frost_forecast | grep -v grep

# 检查资源使用
htop  # 或 top
```

---

## 性能对比

### 标准评估结果

**3小时窗口**：

| 指标 | 旧特征 | 新特征 | 改进 |
|------|--------|--------|------|
| Brier Score | 0.0080 | 0.0054 | ↓ 32.5% |
| ROC-AUC | 0.7289 | 0.8855 | ↑ 21.5% |
| MAE (°C) | 5.7557 | 4.6799 | ↓ 18.7% |
| R² | 0.3477 | 0.5834 | ↑ 67.8% |

**6小时窗口**：

| 指标 | 旧特征 | 新特征 | 改进 |
|------|--------|--------|------|
| Brier Score | 0.0078 | 0.0055 | ↓ 29.5% |
| ROC-AUC | 0.6627 | 0.8806 | ↑ 32.9% |
| MAE (°C) | 6.1708 | 4.6904 | ↓ 24.0% |
| R² | 0.2476 | 0.5807 | ↑ 134.5% |

### LOSO 评估结果

**关键改进**：
- ✅ **ROC-AUC 标准差大幅降低**：从 0.1766 → 0.0244（降低 86%）
- ✅ **温度预测 R² 提升 55.8%**：从 0.35 → 0.54
- ✅ **所有指标的标准差都降低**：跨站点性能更稳定

**3小时窗口（跨站点泛化）**：

| 指标 | 旧特征 | 新特征 | 改进 |
|------|--------|--------|------|
| ROC-AUC (mean ± std) | 0.7289 ± 0.1766 | 0.9019 ± 0.0244 | ↑ 23.7% |
| MAE (mean ± std, °C) | 5.7557 ± 0.3128 | 4.9144 ± 0.2058 | ↓ 14.6% |
| R² (mean ± std) | 0.3477 ± 0.0727 | 0.5416 ± 0.0466 | ↑ 55.8% |

**6小时窗口（跨站点泛化）**：

| 指标 | 旧特征 | 新特征 | 改进 |
|------|--------|--------|------|
| ROC-AUC (mean ± std) | 0.6627 ± 0.1033 | 0.8939 ± 0.0214 | ↑ 34.9% |
| MAE (mean ± std, °C) | 6.1708 ± 0.4426 | 4.9349 ± 0.2035 | ↓ 20.0% |
| R² (mean ± std) | 0.2476 ± 0.0757 | 0.5373 ± 0.0480 | ↑ 117.0% |

### 主要成就

- ✅ **Brier Score**: 改进 30-33%（标准评估）
- ✅ **ROC-AUC**: 提升 21-33%（标准评估），提升 24-35%（LOSO评估）
- ✅ **温度预测 MAE**: 改进 19-24%（标准评估），改进 15-20%（LOSO评估）
- ✅ **温度预测 R²**: 提升 68-135%（标准评估），提升 56-117%（LOSO评估）
- ✅ **跨站点稳定性**: ROC-AUC 标准差降低 79-86%

---

## 特征工程和LOSO的关系

### 问题

**特征工程阶段是否需要做LOSO？**

### 答案

**简短回答**:
- **特征创建 (Feature Creation)**: ❌ **不需要LOSO**
- **预处理 (Preprocessing)**: ✅ **需要LOSO**

### 详细分析

#### 特征创建阶段：不需要LOSO

**原因**：

特征创建是基于时间序列的**本地计算**，不是跨站点统计：

1. **Lag Features** (滞后特征):
   ```python
   # 只使用当前站点的历史数据
   df[f"{col}_lag_6"] = df.groupby("Stn Id")[col].shift(6)
   ```
   - ✅ 无跨站点信息
   - ✅ 每个站点的时间序列本地计算

2. **Rolling Features** (滚动特征):
   ```python
   # 只使用当前站点的滚动窗口
   df[f"{col}_rolling_6h_mean"] = df.groupby("Stn Id")[col].rolling(6).mean()
   ```
   - ✅ 无跨站点信息
   - ✅ 每个站点的时间序列本地计算

3. **Derived Features** (派生特征):
   ```python
   # 只使用当前站点的数据
   df["wind_chill"] = calculate_wind_chill(df["Air Temp (C)"], df["Wind Speed (m/s)"])
   ```
   - ✅ 无跨站点信息
   - ✅ 基于物理公式的计算

4. **Station Features** (站点特征):
   ```python
   # 使用站点元数据（同一站点的所有行相同）
   df["latitude"] = df["Stn Id"].map(station_metadata["latitude"])
   ```
   - ✅ 静态特征（不需要统计）
   - ✅ 同一站点的所有行相同

**关键点**: 特征创建使用 `groupby("Stn Id")` 确保**本地计算** - 每个站点的特征独立计算。

#### 预处理阶段：需要LOSO

**原因**：

预处理需要**统计拟合**（均值、标准差等），可能泄露信息：

1. **StandardScaler**:
   ```python
   # ❌ 错误 - 泄露测试站点信息
   scaler.fit(X_all_stations)  # 使用所有站点
   X_test_scaled = scaler.transform(X_test_station)
   
   # ✅ 正确 - 无泄露
   scaler.fit(X_train_stations)  # 只使用训练站点
   X_test_scaled = scaler.transform(X_test_station)
   ```

2. **Imputation** (缺失值填充):
   ```python
   # ❌ 错误 - 泄露测试站点统计
   mean_value = X_all_stations.mean()  # 使用所有站点
   X_test_imputed = X_test.fillna(mean_value)
   
   # ✅ 正确 - 无泄露
   mean_value = X_train_stations.mean()  # 只使用训练站点
   X_test_imputed = X_test.fillna(mean_value)
   ```

**当前实现**:

在LOSO评估中:
```python
def perform_loso_evaluation(...):
    for train_df, test_df in loso_splits:
        # ✅ 特征创建在train+test上分别完成
        # 但特征创建是本地的（无跨站点统计）
        
        # ✅ 预处理使用LOSO
        X_train, X_test = preprocess_with_loso(
            train_df,  # 只有训练站点
            test_df,   # 只有测试站点
            feature_cols=feature_cols,
            scaling_method=None  # 树模型不需要标准化
        )
        # preprocess_with_loso确保:
        # - Scaler只在train_df上拟合
        # - 测试站点永远不会用于拟合
```

### 数据泄露分析

| 阶段 | 跨站点信息？ | 泄露风险 | 需要LOSO？ |
|------|--------------|----------|------------|
| **特征创建** | ❌ 否 | ✅ 无 | ❌ 不需要 |
| **预处理** | ✅ 是 | ❌ 高 | ✅ 需要 |

**为什么**:
- **特征创建**: 所有特征创建使用 `groupby("Stn Id")` 确保**本地计算**
- **预处理**: 预处理需要统计拟合（均值、标准差、百分位数），**必须**只从训练数据获取

### 当前工作流

#### 标准评估（无LOSO）

```python
# 1. 特征创建（所有数据一起）
df_features = engineer.build_feature_set(df_all_stations, feature_config)
# ✅ 不需要LOSO - 本地计算

# 2. 预处理（可选，树模型不需要）
# 如果需要标准化:
scaler.fit(X_all)  # 标准评估中可以使用（所有数据一起使用）
X_scaled = scaler.transform(X_all)

# 3. 训练/测试划分（基于时间）
train_df, val_df, test_df = time_split(df_features)
# 在train_df上训练，在test_df上测试
```

#### LOSO评估

```python
# 1. 特征创建（所有数据一起）
df_features = engineer.build_feature_set(df_all_stations, feature_config)
# ✅ 不需要LOSO - 本地计算

# 2. LOSO划分
for train_df, test_df in leave_one_station_out(df_features):
    # train_df: 17个站点
    # test_df: 1个站点（完全未见）
    
    # 3. 预处理（使用LOSO）
    X_train, X_test = preprocess_with_loso(
        train_df,  # 只有训练站点
        test_df,   # 只有测试站点
        feature_cols=feature_cols,
        scaling_method=None  # 树模型不需要标准化
    )
    # ✅ LOSO确保:
    # - Scaler只在train_df上拟合
    # - 测试站点永远不会用于拟合
    
    # 4. 训练和评估
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    # 在完全未见的站点上评估
```

### 最佳实践

#### 1. 特征创建

✅ **应该**:
- 在所有数据一起创建特征
- 对时间序列特征使用 `groupby("Stn Id")`
- 保持特征创建逻辑本地到每个站点

❌ **不应该**:
- 使用跨站点统计进行特征创建
- 跨所有站点计算特征的均值/标准差

#### 2. 预处理

✅ **应该**:
- 在LOSO评估中对预处理使用LOSO
- 只在训练站点上拟合scaler/imputer
- 使用训练统计转换测试站点

❌ **不应该**:
- 在LOSO评估中对所有站点拟合预处理
- 使用测试站点统计进行预处理

#### 3. 树模型

✅ **优势**:
- 树模型（LightGBM, XGBoost）不需要标准化
- 可以完全跳过预处理
- 降低泄露风险

```python
# 树模型不需要标准化
X_train, X_test = preprocess_with_loso(
    train_df, test_df,
    scaling_method=None  # ✅ 树模型跳过标准化
)
```

### 总结

| 阶段 | 需要LOSO？ | 原因 |
|------|------------|------|
| **特征创建** | ❌ **不需要** | 本地计算（无跨站点统计） |
| **预处理** | ✅ **需要** | 统计拟合（泄露风险） |
| **训练** | ✅ **需要** | 不同的划分策略 |
| **评估** | ✅ **需要** | 在未见站点上测试 |

**关键要点**:

**特征创建不需要LOSO**，因为:
- ✅ 使用 `groupby("Stn Id")` 进行本地计算
- ✅ 无跨站点统计
- ✅ 无数据泄露风险

**预处理需要LOSO**，因为:
- ⚠️ 需要统计拟合（均值、标准差、百分位数）
- ⚠️ 必须只在训练站点上拟合
- ⚠️ 如果不正确执行，泄露风险很高

**当前实现是正确的**:
- ✅ 特征创建: 所有站点一起（无LOSO）
- ✅ 预处理: LOSO评估中使用LOSO
- ✅ 树模型: 跳过标准化（无泄露风险）

---

## 📚 相关文档

- **[USER_GUIDE.md](USER_GUIDE.md)**: 用户指南
- **[FEATURE_ENGINEERING.md](FEATURE_ENGINEERING.md)**: 特征工程文档
- **[DATA_DOCUMENTATION.md](DATA_DOCUMENTATION.md)**: 数据文档
- **[docs/report/LOSO_EVALUATION_GUIDE.md](report/LOSO_EVALUATION_GUIDE.md)**: LOSO评估详细指南
- **[docs/report/feature_importance_report.md](report/feature_importance_report.md)**: 特征重要性分析报告
- **[docs/report/FEATURE_SELECTION_RECOMMENDATIONS.md](report/FEATURE_SELECTION_RECOMMENDATIONS.md)**: 详细特征选择建议
- **[docs/report/SAMPLING_METHOD_CLARIFICATION.md](report/SAMPLING_METHOD_CLARIFICATION.md)**: 详细采样方法说明
